{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0c598c0-38af-4765-a405-2787ad2de2e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "if torch.cuda.is_available():\n",
    "    torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1956f910-24ce-4ceb-92e3-1a70e6284790",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Black', 'Blue', 'Brown', 'Green', 'Grey', 'Orange', 'Pink', 'Purple', 'Red', 'White', 'Yellow'] Blue\n"
     ]
    }
   ],
   "source": [
    "rgb = []\n",
    "colors = []\n",
    "categories = []\n",
    "for data in open(\"labels.csv\", \"r\").read().splitlines()[1:]:\n",
    "    r, g, b, label = data.split(\",\")\n",
    "    rgb.append((float(r)/255, float(g)/255, float(b)/255))\n",
    "    colors.append(label)\n",
    "\n",
    "categories = sorted(list(set(colors)))\n",
    "colors_enc = [categories.index(c) for c in colors]\n",
    "print(categories, colors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bafbe148-dfd4-406b-874a-383fa4d6894d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5052, 3]) torch.Size([5052, 11])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor(rgb).float()\n",
    "labels = F.one_hot(torch.tensor(colors_enc)).float()\n",
    "\n",
    "hidden_layer_dim = 50\n",
    "\n",
    "W1 = torch.randn((3, hidden_layer_dim)) * (5/3)/(3**0.5)\n",
    "W2 = torch.randn((hidden_layer_dim, labels.shape[1])) * 0.01\n",
    "print(inputs.shape, labels.shape)\n",
    "\n",
    "# BatchNorm parameters\n",
    "bngain = torch.ones((1, hidden_layer_dim))\n",
    "bnbias = torch.zeros((1, hidden_layer_dim))\n",
    "bnmean_running = torch.zeros((1, hidden_layer_dim))\n",
    "bnstd_running = torch.ones((1, hidden_layer_dim))\n",
    "\n",
    "parameters = [W1, W2, bngain, bnbias]\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78a3174e-5675-4bea-8af1-f4e47953acd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3981, grad_fn=<DivBackward1>)\n",
      "tensor(2.2538, grad_fn=<DivBackward1>)\n",
      "tensor(2.2360, grad_fn=<DivBackward1>)\n",
      "tensor(2.2248, grad_fn=<DivBackward1>)\n",
      "tensor(2.2140, grad_fn=<DivBackward1>)\n",
      "tensor(2.2026, grad_fn=<DivBackward1>)\n",
      "tensor(2.1972, grad_fn=<DivBackward1>)\n",
      "tensor(2.1933, grad_fn=<DivBackward1>)\n",
      "tensor(2.1897, grad_fn=<DivBackward1>)\n",
      "tensor(2.1859, grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    hpreact = inputs @ W1\n",
    "    bnmeani = hpreact.mean(0, keepdim=True)\n",
    "    bnstdi = hpreact.std(0, keepdim=True)\n",
    "    hpreact = bngain * (hpreact - bnmeani) / bnstdi + bnbias\n",
    "    with torch.no_grad():\n",
    "        bnmean_running = 0.999 * bnmean_running + 0.001 * bnmeani\n",
    "        bnstd_running = 0.999 * bnstd_running + 0.001 * bnstdi\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = torch.tanh(h @ W2)\n",
    "    loss = F.cross_entropy(logits.softmax(dim=1), labels)\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(loss)\n",
    "    \n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    lr = 0.1 if i < 100000 else 0.01\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "    \n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15cfc2b4-06c3-46c4-a01b-628531c652d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0092, -0.0400, -0.0079, -0.0507, -0.0257, -0.1004, -0.0676,  0.0631,\n",
      "          0.0312, -0.0460,  0.0321]], grad_fn=<TanhBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0934, 0.0889, 0.0918, 0.0879, 0.0901, 0.0837, 0.0865, 0.0985, 0.0954,\n",
       "         0.0883, 0.0955]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color = torch.tensor([255,0,0]).float()\n",
    "hpreact = color @ W1\n",
    "hpreact = bngain * (hpreact - bnmean_running) / bnstd_running + bnbias\n",
    "h = torch.tanh(hpreact)\n",
    "logits = torch.tanh(h @ W2)\n",
    "print(logits)\n",
    "logits.softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e9084ce-87ad-4abd-bcbb-23f79f7649ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  # pass the training set through\n",
    "  hpreact = inputs @ W1 # + b1\n",
    "  # measure the mean/std over the entire training set\n",
    "  bnmean = hpreact.mean(0, keepdim=True)\n",
    "  bnstd = hpreact.std(0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90ae780f-14b5-42c1-a5d7-97c9d5931123",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9517, -1.0000,  1.0000, -0.9990, -0.9504,  0.9628,  0.8474,  0.0220,\n",
      "          0.9986, -0.9632, -0.7376]], grad_fn=<TanhBackward0>)\n",
      "tensor([[0.0280, 0.0267, 0.1973, 0.0267, 0.0281, 0.1901, 0.1694, 0.0742, 0.1970,\n",
      "         0.0277, 0.0347]], grad_fn=<SoftmaxBackward0>)\n",
      "Brown\n"
     ]
    }
   ],
   "source": [
    "color = torch.tensor([1,0,0]).float()\n",
    "hpreact = color @ W1\n",
    "hpreact = bngain * (hpreact - bnmean_running) / bnstd_running + bnbias\n",
    "h = torch.tanh(hpreact)\n",
    "logits = torch.tanh(h @ W2)\n",
    "print(logits)\n",
    "probs = logits.softmax(dim=1)\n",
    "print(probs)\n",
    "print(categories[torch.argmax(probs)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
